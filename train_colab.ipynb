{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 获取计算硬件\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "# 数据集文件夹路径\n",
    "dataset_dir = '/mnt/d/dataset/c100v2'\n",
    "select = 'fc'\n",
    "# 训练轮次 Epoch\n",
    "EPOCHS = 100\n",
    "\n",
    "# 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "test_path = os.path.join(dataset_dir, 'val')\n",
    "\n",
    "# 载入训练集\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "# 载入测试集\n",
    "test_dataset = datasets.ImageFolder(test_path, test_transform)\n",
    "\n",
    "# 各类别名称\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)\n",
    "# 映射关系：类别 到 索引号\n",
    "train_dataset.class_to_idx\n",
    "# 映射关系：索引号 到 类别\n",
    "idx_to_labels = {y: x for x, y in train_dataset.class_to_idx.items()}\n",
    "np.save('idx_to_labels.npy', idx_to_labels)\n",
    "np.save('labels_to_idx.npy', train_dataset.class_to_idx)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 训练集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                          )\n",
    "\n",
    "# 测试集的数据加载器\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                         )\n",
    "\n",
    "if select == 'fc':\n",
    "    model = models.resnet50(pretrained=True)  # 载入预训练模型\n",
    "\n",
    "    # 修改全连接层，使得全连接层的输出与当前数据集类别数对应\n",
    "    # 新建的层默认 requires_grad=True\n",
    "    model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "    model.fc\n",
    "    # 只微调训练最后一层全连接层的参数，其它层冻结\n",
    "    optimizer = optim.Adam(model.fc.parameters())\n",
    "\n",
    "if select == 'all':\n",
    "    model = models.resnet50(pretrained=True)  # 载入预训练模型\n",
    "    model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "if select == 'full':\n",
    "    model = models.resnet50(pretrained=False)  # 只载入模型结构，不载入预训练权重参数\n",
    "    model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "model = model.to(device)\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 学习率降低策略\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "\n",
    "def train_one_batch(images, labels):\n",
    "    '''\n",
    "    运行一个 batch 的训练，返回当前 batch 的训练日志\n",
    "    '''\n",
    "\n",
    "    # 获得一个 batch 的数据和标注\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = model(images)  # 输入模型，执行前向预测\n",
    "    loss = criterion(outputs, labels)  # 计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "\n",
    "    # 优化更新权重\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 获取当前 batch 的标签类别和预测类别\n",
    "    _, preds = torch.max(outputs, 1)  # 获得当前 batch 所有图像的预测类别\n",
    "    preds = preds.cpu().numpy()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "\n",
    "    log_train = {}\n",
    "    log_train['epoch'] = epoch\n",
    "    log_train['batch'] = batch_idx\n",
    "    # 计算分类评估指标\n",
    "    log_train['train_loss'] = loss\n",
    "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
    "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
    "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
    "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
    "\n",
    "    return log_train\n",
    "\n",
    "\n",
    "def evaluate_testset():\n",
    "    '''\n",
    "    在整个测试集上评估，返回分类评估指标日志\n",
    "    '''\n",
    "\n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:  # 生成一个 batch 的数据和标注\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)  # 输入模型，执行前向预测\n",
    "\n",
    "            # 获取整个测试集的标签类别和预测类别\n",
    "            _, preds = torch.max(outputs, 1)  # 获得当前 batch 所有图像的预测类别\n",
    "            preds = preds.cpu().numpy()\n",
    "            loss = criterion(outputs, labels)  # 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            labels_list.extend(labels)\n",
    "            preds_list.extend(preds)\n",
    "\n",
    "    log_test = {}\n",
    "    log_test['epoch'] = epoch\n",
    "\n",
    "    # 计算分类评估指标\n",
    "    log_test['test_loss'] = np.mean(loss_list)\n",
    "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
    "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
    "\n",
    "    return log_test\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "batch_idx = 0\n",
    "best_test_accuracy = 0\n",
    "\n",
    "# 训练日志-训练集\n",
    "df_train_log = pd.DataFrame()\n",
    "log_train = {}\n",
    "log_train['epoch'] = 0\n",
    "log_train['batch'] = 0\n",
    "images, labels = next(iter(train_loader))\n",
    "log_train.update(train_one_batch(images, labels))\n",
    "df_train_log = df_train_log._append(log_train, ignore_index=True)\n",
    "\n",
    "df_test_log = pd.DataFrame()\n",
    "log_test = {}\n",
    "log_test['epoch'] = 0\n",
    "log_test.update(evaluate_testset())\n",
    "df_test_log = df_test_log._append(log_test, ignore_index=True)\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=f'c100resnet50-{select}', name=time.strftime('%m%d%H%M%S'))\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "\n",
    "    ## 训练阶段\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader):  # 获得一个 batch 的数据和标注\n",
    "        batch_idx += 1\n",
    "        log_train = train_one_batch(images, labels)\n",
    "        df_train_log = df_train_log._append(log_train, ignore_index=True)\n",
    "        wandb.log(log_train)\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    ## 测试阶段\n",
    "    model.eval()\n",
    "    log_test = evaluate_testset()\n",
    "    df_test_log = df_test_log._append(log_test, ignore_index=True)\n",
    "    wandb.log(log_test)\n",
    "\n",
    "    # 保存最新的最佳模型文件\n",
    "    if log_test['test_accuracy'] > best_test_accuracy:\n",
    "        # 删除旧的最佳模型文件(如有)\n",
    "        old_best_checkpoint_path = 'checkpoint/best-{:.3f}.pth'.format(best_test_accuracy)\n",
    "        if os.path.exists(old_best_checkpoint_path):\n",
    "            os.remove(old_best_checkpoint_path)\n",
    "        # 保存新的最佳模型文件\n",
    "        best_test_accuracy = log_test['test_accuracy']\n",
    "        new_best_checkpoint_path = 'checkpoint/best-{:.3f}.pth'.format(log_test['test_accuracy'])\n",
    "        torch.save(model, new_best_checkpoint_path)\n",
    "        print('保存新的最佳模型', 'checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))\n",
    "        # best_test_accuracy = log_test['test_accuracy']\n",
    "\n",
    "df_train_log.to_csv('训练日志-训练集.csv', encoding='utf_8_sig', index=False)\n",
    "df_test_log.to_csv('训练日志-测试集.csv', encoding='utf_8_sig', index=False)\n",
    "\n",
    "model = torch.load('checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))\n",
    "\n",
    "model.eval()\n",
    "print(evaluate_testset())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
